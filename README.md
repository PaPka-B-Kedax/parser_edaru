# Асинхронный парсер рецептов Eda.ru

Этот скрипт собирает данные о рецептах (ID, название, ссылка, время готовки, порции)
из указанной категории на сайте `eda.ru`.

Он использует `httpx` и `asyncio` для высокой скорости работы
(с `Semaphore` для "вежливости") и `jmespath` для безопасного
извлечения данных.

## 1. Установка

1. Клонируйте репозиторий или скачайте .zip.
2. Создайте виртуальное окружение:
   `python -m venv venv`
3. Активируйте его:
   * Windows: `venv\Scripts\activate`
   * Mac/Linux: `source venv/bin/activate`
4. Установите "детали" ("список покупок"):
   `pip install -r requirements.txt`

## 2. Конфигурация (ОБЯЗАТЕЛЬНО)

Перед *первым* запуском, откройте файл `config.py`:

1. **Обновите `HEADERS`**:
   * Зайдите на `eda.ru` в браузере.
   * Откройте F12 (DevTools) -> Network -> Fetch/XHR.
   * Найдите запрос `graphql`.
   * Скопируйте *актуальные* значения `Cookie` и `User-Agent`
     и *вставьте* их в `config.py`.

## 3. Запуск

Скрипт запускается из *терминала* (командной строки).

**Пример 1 (Парсинг "по умолчанию" - Супы, 3 страницы):**
`python main.py --limit 3`

**Пример 2 (Парсинг "Салатов" - все страницы):**
`python main.py --category_id 509`

### Аргументы (Кнопки):

* `-c`, `--category_id` (Опциональный):
  * ID категории для парсинга.
  * **По умолчанию: `538` (Супы).**
  * Примеры: `536` (Салаты), `541` (Выпечка и десерты).
* `-l`, `--limit` (Опциональный):
  * Ограничить парсинг N первыми страницами.
  * **По умолчанию: `0` (парсить *все* страницы).**

## 4. Результат

* Скрипт создаст файл `edaru.xlsx` (название в `config.py`)
  с отформатированными данными.
* Скрипт создаст "черный ящик" `parser.log` со *всеми* техническими деталями (включая `DEBUG`-сообщения).
